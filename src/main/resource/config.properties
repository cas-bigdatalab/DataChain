#kafka
zookeeper.connect=10.0.71.20:2181,10.0.71.26:2181,10.0.71.27:2181
group.id=test-consumer-group

#spark streaming seconds
duration=1

#mysql
mysql_url=jdbc:mysql://10.0.71.7:3306/
mysql_user=root
mysql_password=root
mysql_driver=org.apache.spark.sql.jdbc


#mongodb
mongo_host=10.0.71.7:27017
mongo_driver=com.stratio.datasource.mongodb

#hivedb
hive_db=hive,hbase,impala

mysql_create_sql=CREATE TEMPORARY TABLE test USING %using% OPTIONS ( url '%url%', dbtable '%table%')
mongo_create_sql=CREATE TEMPORARY TABLE test( %columns% ) USING %using% OPTIONS ( host '%host%', database '%db%', collection '%table%')

#spark param
spark_host=10.0.71.1
master=spark://10.0.71.1:7077
executor-memory=10G
total-executor-cores=24
spark_home=/opt/spark

#task param
realtime_class=cn.cnic.bigdatalab.compute.RealTime.Kafka2SparkStreaming
realtime_path=/opt/datachain.jar
offline_class=cn.cnic.bigdatalab.compute.Offline
offline_path=/opt/datachain.jar

#flume param
flume_home=/usr/lib/flume
flume_conf_localDir=/tmp

